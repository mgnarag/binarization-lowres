{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/binarization-lowres/blob/main/From_Arki_model3_50epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gXM5CNP5BaYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7526df18-4889-4157-80a0-e7de2e1576f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/My Drive/Architectural_designs/From Arki/\""
      ],
      "metadata": {
        "id": "xiAgOwvmBcjr",
        "outputId": "6bd68c2c-3941-4602-b276-08c99cca4527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 313490484_646790150357239_663796780442369775_n.jpg\n",
            " 361079911_248325231393045_2145216296096417082_n.jpg\n",
            "'Applied Physics 184 FX-2'\n",
            " Architectural_designs\n",
            "'BS Applied Physics'\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'CONSENT_NARAG_MARK JEREMY_G.pdf'\n",
            " CONSENT_NARAG_MARKJEREMY_G.pdf\n",
            "'Dorm bill.png'\n",
            "'Getting started.pdf'\n",
            " IMG_6546.PNG\n",
            "'IMG_9359 (1).PNG'\n",
            " IMG_9359.PNG\n",
            "'Information Sharing Consent Form - NARAG.pdf'\n",
            "'Information Sharing Consent Form.pdf'\n",
            "'[Journal of Cultural Heritage] Discovering artistic influences of painters'\n",
            "'MS PHYSICS'\n",
            "'MS Thesis videos'\n",
            "'NARAG, MARK JEREMY, GACIAS.gdoc'\n",
            "'NARAG, MARK JEREMY, GACIAS.pdf'\n",
            "'NARAG, MARK JEREMY.jpg'\n",
            " NIP_Narag_MarkJeremy_Consent.pdf\n",
            " NIP_Narag_MarkJeremy_Informal.jpg\n",
            " NIP_Narag_MarkJeremy_Sablay.jpg\n",
            "'PEHA 2021 Consent Form (fillable).pdf'\n",
            "'PHOTO_NARAG_MARK JEREMY_G.jpg'\n",
            " PHOTO_NARAG_MARKJEREMY_G.jpg\n",
            "'Physics 265'\n",
            "'Physics 301 2S AY2122'\n",
            "'Physics 305 Data Driven Astronomy'\n",
            "'Research files'\n",
            "'Screen Shot 2022-08-31 at 10.46.42.png'\n",
            "'Screen Shot 2022-09-13 at 12.40.21.png'\n",
            "'Screen Shot 2022-09-13 at 12.43.14.png'\n",
            "'SPP 2022'\n",
            "'Untitled document.gdoc'\n",
            "'Vaccination Card (1).jpg'\n",
            "'Vaccination Card.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "epoch = 500\n",
        "model_number = 3\n",
        "size = 64\n",
        "\n",
        "def crop(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "\n",
        "    for j in np.arange(0,int(height/size)+1,1.3):\n",
        "        for i in np.arange(0,int(width/size)+1,1.3):\n",
        "            im1 = im.crop((0 + (size*i), 0 + (size*j), size + (size*i), size + (size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "\n",
        "    for j in np.arange(0,int(height/size)+1,1.3):\n",
        "        for i in np.arange(0,int(width/size)+1,1.3):\n",
        "            im1 = im.crop((0 + (size*i), 0 + (size*j), size + (size*i), size + (size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            #im1 = im1/4\n",
        "            data.append(im1)\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "input = np.array(crop_(ImageOps.grayscale(Image.open(file_path + \"Rizal_input.png\"))))\n",
        "print(\"Done reading the input of size = \", input.shape)\n",
        "\n",
        "output = np.array(crop(ImageOps.grayscale(Image.open(file_path + \"Rizal_output.png\"))))\n",
        "print(\"Done reading the output of size = \", input.shape)\n",
        "\n",
        "train_input = []\n",
        "test_input = []\n",
        "for i in range(0,len(input)):\n",
        "    if i % 4 == 0:\n",
        "        test_input.append(input[i])\n",
        "    else:\n",
        "        train_input.append(input[i])\n",
        "\n",
        "train_input = np.array(train_input)\n",
        "test_input = np.array(test_input)\n",
        "\n",
        "print(\"Done reading the train input of size = \", train_input.shape)\n",
        "print(\"Done reading the test input of size = \", test_input.shape)\n",
        "\n",
        "train_output = []\n",
        "test_output = []\n",
        "for i in range(0,len(output)):\n",
        "    if i % 4 == 0:\n",
        "        test_output.append(output[i])\n",
        "    else:\n",
        "        train_output.append(output[i])\n",
        "\n",
        "train_output = np.array(train_output)\n",
        "test_output = np.array(test_output)\n",
        "\n",
        "print(\"Done reading the train output of size = \", train_input.shape)\n",
        "print(\"Done reading the test output of size = \", test_input.shape)"
      ],
      "metadata": {
        "id": "MjpPVdDyBeby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24e2511-a197-484a-9df1-a1810470c455"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (115430400 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done reading the input of size =  (16895, 64, 64)\n",
            "Done reading the output of size =  (16895, 64, 64)\n",
            "Done reading the train input of size =  (12671, 64, 64)\n",
            "Done reading the test input of size =  (4224, 64, 64)\n",
            "Done reading the train output of size =  (12671, 64, 64)\n",
            "Done reading the test output of size =  (4224, 64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(0,10):\n",
        "\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"input\")\n",
        "    plt.imshow((train_input[i+2000]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    bx = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"output\")\n",
        "    plt.imshow((train_output[i+2000]))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "zUKPw12vBfw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "bf25add3-0fc0-4da2-a65c-055a81fd9a47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "class autoenc(Model):\n",
        "  def __init__(self):\n",
        "    super(autoenc, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Input(shape=(size, size, 1)),\n",
        "      layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2),\n",
        "      layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=2),\n",
        "      layers.Conv2D(256, (3, 3), activation='relu', padding='same', strides=2)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(256, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2DTranspose(128, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2DTranspose(64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = autoenc()\n",
        "\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "model = autoencoder.fit(train_input, train_output,\n",
        "                epochs=epoch,\n",
        "                shuffle=True,\n",
        "                validation_data=(test_input, test_output))\n",
        "\n",
        "autoencoder.encoder.summary()\n",
        "\n",
        "\n",
        "autoencoder.save(file_path + '1 Models/' + 'autoencoder_' + str(model_number)+'_500')\n",
        "\n",
        "loss = model.history['loss']\n",
        "loss = pd.DataFrame(loss)\n",
        "loss.to_csv(file_path + '2 Loss/'+'loss_'+ str(model_number) + '_500.csv')\n",
        "val_loss = model.history['val_loss']\n",
        "val_loss = pd.DataFrame(val_loss)\n",
        "val_loss.to_csv(file_path + '3 Validation loss/' +'val_loss_'+ str(model_number) + '_500.csv')\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        "\n",
        "print(\"The time of execution of above program is :\",\n",
        "      (end-start), \"seconds\")\n"
      ],
      "metadata": {
        "id": "yr5u2kBlBhYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec62c40-5d7d-48ef-da6f-f84f000162aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "396/396 [==============================] - 24s 28ms/step - loss: 0.0546 - val_loss: 0.0313\n",
            "Epoch 2/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0261 - val_loss: 0.0191\n",
            "Epoch 3/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0186 - val_loss: 0.0177\n",
            "Epoch 4/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0178 - val_loss: 0.0172\n",
            "Epoch 5/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0174 - val_loss: 0.0174\n",
            "Epoch 6/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0172 - val_loss: 0.0173\n",
            "Epoch 7/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0169 - val_loss: 0.0168\n",
            "Epoch 8/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0168 - val_loss: 0.0170\n",
            "Epoch 9/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0166 - val_loss: 0.0169\n",
            "Epoch 10/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0165 - val_loss: 0.0167\n",
            "Epoch 11/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0164 - val_loss: 0.0167\n",
            "Epoch 12/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0162 - val_loss: 0.0163\n",
            "Epoch 13/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0161 - val_loss: 0.0163\n",
            "Epoch 14/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0161 - val_loss: 0.0168\n",
            "Epoch 15/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0160 - val_loss: 0.0163\n",
            "Epoch 16/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0158 - val_loss: 0.0162\n",
            "Epoch 17/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0158 - val_loss: 0.0161\n",
            "Epoch 18/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0157 - val_loss: 0.0164\n",
            "Epoch 19/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0155 - val_loss: 0.0162\n",
            "Epoch 20/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0154 - val_loss: 0.0161\n",
            "Epoch 21/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0152 - val_loss: 0.0160\n",
            "Epoch 22/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0151 - val_loss: 0.0163\n",
            "Epoch 23/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0151 - val_loss: 0.0160\n",
            "Epoch 24/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0149 - val_loss: 0.0164\n",
            "Epoch 25/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0150 - val_loss: 0.0162\n",
            "Epoch 26/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0147 - val_loss: 0.0161\n",
            "Epoch 27/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0144 - val_loss: 0.0163\n",
            "Epoch 28/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0143 - val_loss: 0.0162\n",
            "Epoch 29/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0141 - val_loss: 0.0164\n",
            "Epoch 30/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0139 - val_loss: 0.0164\n",
            "Epoch 31/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0138 - val_loss: 0.0166\n",
            "Epoch 32/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0136 - val_loss: 0.0164\n",
            "Epoch 33/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0134 - val_loss: 0.0165\n",
            "Epoch 34/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0132 - val_loss: 0.0167\n",
            "Epoch 35/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0131 - val_loss: 0.0168\n",
            "Epoch 36/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0128 - val_loss: 0.0168\n",
            "Epoch 37/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0127 - val_loss: 0.0169\n",
            "Epoch 38/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0124 - val_loss: 0.0170\n",
            "Epoch 39/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0122 - val_loss: 0.0171\n",
            "Epoch 40/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0122 - val_loss: 0.0173\n",
            "Epoch 41/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0118 - val_loss: 0.0174\n",
            "Epoch 42/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0116 - val_loss: 0.0176\n",
            "Epoch 43/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0115 - val_loss: 0.0174\n",
            "Epoch 44/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0113 - val_loss: 0.0176\n",
            "Epoch 45/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0111 - val_loss: 0.0178\n",
            "Epoch 46/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0110 - val_loss: 0.0178\n",
            "Epoch 47/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0108 - val_loss: 0.0182\n",
            "Epoch 48/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0106 - val_loss: 0.0180\n",
            "Epoch 49/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0105 - val_loss: 0.0182\n",
            "Epoch 50/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0103 - val_loss: 0.0184\n",
            "Epoch 51/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0102 - val_loss: 0.0183\n",
            "Epoch 52/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0101 - val_loss: 0.0185\n",
            "Epoch 53/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0099 - val_loss: 0.0187\n",
            "Epoch 54/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0098 - val_loss: 0.0187\n",
            "Epoch 55/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0096 - val_loss: 0.0186\n",
            "Epoch 56/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0095 - val_loss: 0.0187\n",
            "Epoch 57/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0094 - val_loss: 0.0190\n",
            "Epoch 58/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0092 - val_loss: 0.0190\n",
            "Epoch 59/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0092 - val_loss: 0.0191\n",
            "Epoch 60/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0091 - val_loss: 0.0191\n",
            "Epoch 61/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0089 - val_loss: 0.0191\n",
            "Epoch 62/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0088 - val_loss: 0.0194\n",
            "Epoch 63/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0087 - val_loss: 0.0194\n",
            "Epoch 64/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0086 - val_loss: 0.0195\n",
            "Epoch 65/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0085 - val_loss: 0.0194\n",
            "Epoch 66/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0084 - val_loss: 0.0195\n",
            "Epoch 67/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0083 - val_loss: 0.0197\n",
            "Epoch 68/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0082 - val_loss: 0.0199\n",
            "Epoch 69/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0081 - val_loss: 0.0199\n",
            "Epoch 70/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0081 - val_loss: 0.0200\n",
            "Epoch 71/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0079 - val_loss: 0.0201\n",
            "Epoch 72/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0079 - val_loss: 0.0201\n",
            "Epoch 73/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0081 - val_loss: 0.0202\n",
            "Epoch 74/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0078 - val_loss: 0.0202\n",
            "Epoch 75/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0076 - val_loss: 0.0202\n",
            "Epoch 76/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0075 - val_loss: 0.0203\n",
            "Epoch 77/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0074 - val_loss: 0.0205\n",
            "Epoch 78/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0074 - val_loss: 0.0203\n",
            "Epoch 79/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0073 - val_loss: 0.0205\n",
            "Epoch 80/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0073 - val_loss: 0.0205\n",
            "Epoch 81/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0072 - val_loss: 0.0206\n",
            "Epoch 82/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0071 - val_loss: 0.0207\n",
            "Epoch 83/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0071 - val_loss: 0.0208\n",
            "Epoch 84/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0071 - val_loss: 0.0207\n",
            "Epoch 85/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0070 - val_loss: 0.0209\n",
            "Epoch 86/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0069 - val_loss: 0.0208\n",
            "Epoch 87/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0068 - val_loss: 0.0209\n",
            "Epoch 88/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0068 - val_loss: 0.0209\n",
            "Epoch 89/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0067 - val_loss: 0.0210\n",
            "Epoch 90/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0067 - val_loss: 0.0210\n",
            "Epoch 91/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0066 - val_loss: 0.0210\n",
            "Epoch 92/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0066 - val_loss: 0.0210\n",
            "Epoch 93/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0065 - val_loss: 0.0212\n",
            "Epoch 94/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0066 - val_loss: 0.0212\n",
            "Epoch 95/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0064 - val_loss: 0.0213\n",
            "Epoch 96/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0064 - val_loss: 0.0211\n",
            "Epoch 97/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0063 - val_loss: 0.0213\n",
            "Epoch 98/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0062 - val_loss: 0.0214\n",
            "Epoch 99/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0062 - val_loss: 0.0214\n",
            "Epoch 100/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0062 - val_loss: 0.0214\n",
            "Epoch 101/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0061 - val_loss: 0.0215\n",
            "Epoch 102/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0061 - val_loss: 0.0215\n",
            "Epoch 103/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0061 - val_loss: 0.0214\n",
            "Epoch 104/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0060 - val_loss: 0.0217\n",
            "Epoch 105/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0060 - val_loss: 0.0217\n",
            "Epoch 106/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0060 - val_loss: 0.0217\n",
            "Epoch 107/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0059 - val_loss: 0.0218\n",
            "Epoch 108/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0059 - val_loss: 0.0217\n",
            "Epoch 109/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0058 - val_loss: 0.0217\n",
            "Epoch 110/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0058 - val_loss: 0.0218\n",
            "Epoch 111/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0058 - val_loss: 0.0217\n",
            "Epoch 112/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0057 - val_loss: 0.0219\n",
            "Epoch 113/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0057 - val_loss: 0.0219\n",
            "Epoch 114/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0057 - val_loss: 0.0220\n",
            "Epoch 115/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0056 - val_loss: 0.0219\n",
            "Epoch 116/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0056 - val_loss: 0.0219\n",
            "Epoch 117/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0056 - val_loss: 0.0221\n",
            "Epoch 118/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0055 - val_loss: 0.0219\n",
            "Epoch 119/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0055 - val_loss: 0.0221\n",
            "Epoch 120/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0055 - val_loss: 0.0221\n",
            "Epoch 121/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0054 - val_loss: 0.0220\n",
            "Epoch 122/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0054 - val_loss: 0.0221\n",
            "Epoch 123/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0054 - val_loss: 0.0222\n",
            "Epoch 124/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0054 - val_loss: 0.0221\n",
            "Epoch 125/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0053 - val_loss: 0.0223\n",
            "Epoch 126/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0053 - val_loss: 0.0222\n",
            "Epoch 127/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0053 - val_loss: 0.0222\n",
            "Epoch 128/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0053 - val_loss: 0.0223\n",
            "Epoch 129/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0052 - val_loss: 0.0223\n",
            "Epoch 130/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0052 - val_loss: 0.0224\n",
            "Epoch 131/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0052 - val_loss: 0.0224\n",
            "Epoch 132/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0052 - val_loss: 0.0223\n",
            "Epoch 133/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0051 - val_loss: 0.0226\n",
            "Epoch 134/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0052 - val_loss: 0.0224\n",
            "Epoch 135/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0051 - val_loss: 0.0223\n",
            "Epoch 136/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0050 - val_loss: 0.0225\n",
            "Epoch 137/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0050 - val_loss: 0.0226\n",
            "Epoch 138/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0050 - val_loss: 0.0227\n",
            "Epoch 139/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0050 - val_loss: 0.0227\n",
            "Epoch 140/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0050 - val_loss: 0.0224\n",
            "Epoch 141/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0049 - val_loss: 0.0225\n",
            "Epoch 142/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0049 - val_loss: 0.0224\n",
            "Epoch 143/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0049 - val_loss: 0.0227\n",
            "Epoch 144/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0049 - val_loss: 0.0225\n",
            "Epoch 145/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0048 - val_loss: 0.0227\n",
            "Epoch 146/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0049 - val_loss: 0.0225\n",
            "Epoch 147/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0048 - val_loss: 0.0225\n",
            "Epoch 148/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0048 - val_loss: 0.0226\n",
            "Epoch 149/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0047 - val_loss: 0.0228\n",
            "Epoch 150/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0048 - val_loss: 0.0227\n",
            "Epoch 151/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0047 - val_loss: 0.0226\n",
            "Epoch 152/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0047 - val_loss: 0.0227\n",
            "Epoch 153/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0046 - val_loss: 0.0228\n",
            "Epoch 154/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0047 - val_loss: 0.0228\n",
            "Epoch 155/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0046 - val_loss: 0.0228\n",
            "Epoch 156/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0047 - val_loss: 0.0228\n",
            "Epoch 157/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0046 - val_loss: 0.0229\n",
            "Epoch 158/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0046 - val_loss: 0.0229\n",
            "Epoch 159/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0045 - val_loss: 0.0229\n",
            "Epoch 160/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0046 - val_loss: 0.0228\n",
            "Epoch 161/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0045 - val_loss: 0.0229\n",
            "Epoch 162/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0045 - val_loss: 0.0229\n",
            "Epoch 163/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0046 - val_loss: 0.0229\n",
            "Epoch 164/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0045 - val_loss: 0.0229\n",
            "Epoch 165/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0044 - val_loss: 0.0228\n",
            "Epoch 166/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0045 - val_loss: 0.0230\n",
            "Epoch 167/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0045 - val_loss: 0.0229\n",
            "Epoch 168/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0045 - val_loss: 0.0229\n",
            "Epoch 169/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0044 - val_loss: 0.0229\n",
            "Epoch 170/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0044 - val_loss: 0.0230\n",
            "Epoch 171/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0044 - val_loss: 0.0231\n",
            "Epoch 172/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0044 - val_loss: 0.0229\n",
            "Epoch 173/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0043 - val_loss: 0.0230\n",
            "Epoch 174/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0044 - val_loss: 0.0230\n",
            "Epoch 175/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0043 - val_loss: 0.0230\n",
            "Epoch 176/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0043 - val_loss: 0.0232\n",
            "Epoch 177/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0043 - val_loss: 0.0231\n",
            "Epoch 178/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0042 - val_loss: 0.0230\n",
            "Epoch 179/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0043 - val_loss: 0.0233\n",
            "Epoch 180/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0042 - val_loss: 0.0231\n",
            "Epoch 181/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0042 - val_loss: 0.0230\n",
            "Epoch 182/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0042 - val_loss: 0.0231\n",
            "Epoch 183/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0042 - val_loss: 0.0231\n",
            "Epoch 184/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0042 - val_loss: 0.0234\n",
            "Epoch 185/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0042 - val_loss: 0.0232\n",
            "Epoch 186/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0043 - val_loss: 0.0230\n",
            "Epoch 187/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0041 - val_loss: 0.0233\n",
            "Epoch 188/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0041 - val_loss: 0.0232\n",
            "Epoch 189/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0041 - val_loss: 0.0232\n",
            "Epoch 190/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0041 - val_loss: 0.0233\n",
            "Epoch 191/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0041 - val_loss: 0.0233\n",
            "Epoch 192/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0040 - val_loss: 0.0233\n",
            "Epoch 193/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0041 - val_loss: 0.0234\n",
            "Epoch 194/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0040 - val_loss: 0.0234\n",
            "Epoch 195/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0041 - val_loss: 0.0233\n",
            "Epoch 196/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0040 - val_loss: 0.0233\n",
            "Epoch 197/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0040 - val_loss: 0.0234\n",
            "Epoch 198/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0040 - val_loss: 0.0234\n",
            "Epoch 199/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0039 - val_loss: 0.0234\n",
            "Epoch 200/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0040 - val_loss: 0.0233\n",
            "Epoch 201/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0040 - val_loss: 0.0235\n",
            "Epoch 202/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0040 - val_loss: 0.0234\n",
            "Epoch 203/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0039 - val_loss: 0.0234\n",
            "Epoch 204/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0039 - val_loss: 0.0234\n",
            "Epoch 205/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0039 - val_loss: 0.0235\n",
            "Epoch 206/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0039 - val_loss: 0.0234\n",
            "Epoch 207/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0039 - val_loss: 0.0235\n",
            "Epoch 208/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0039 - val_loss: 0.0236\n",
            "Epoch 209/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0039 - val_loss: 0.0235\n",
            "Epoch 210/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0038 - val_loss: 0.0235\n",
            "Epoch 211/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0038 - val_loss: 0.0235\n",
            "Epoch 212/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0039 - val_loss: 0.0235\n",
            "Epoch 213/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0038 - val_loss: 0.0236\n",
            "Epoch 214/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0038 - val_loss: 0.0236\n",
            "Epoch 215/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0038 - val_loss: 0.0236\n",
            "Epoch 216/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0038 - val_loss: 0.0236\n",
            "Epoch 217/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0038 - val_loss: 0.0234\n",
            "Epoch 218/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0037 - val_loss: 0.0236\n",
            "Epoch 219/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0037 - val_loss: 0.0237\n",
            "Epoch 220/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0038 - val_loss: 0.0235\n",
            "Epoch 221/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0038 - val_loss: 0.0235\n",
            "Epoch 222/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0037 - val_loss: 0.0235\n",
            "Epoch 223/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0037 - val_loss: 0.0237\n",
            "Epoch 224/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0037 - val_loss: 0.0237\n",
            "Epoch 225/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0037 - val_loss: 0.0237\n",
            "Epoch 226/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0037 - val_loss: 0.0238\n",
            "Epoch 227/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0037 - val_loss: 0.0237\n",
            "Epoch 228/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0037 - val_loss: 0.0237\n",
            "Epoch 229/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0036 - val_loss: 0.0236\n",
            "Epoch 230/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0037 - val_loss: 0.0238\n",
            "Epoch 231/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0036 - val_loss: 0.0236\n",
            "Epoch 232/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0036 - val_loss: 0.0238\n",
            "Epoch 233/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0036 - val_loss: 0.0236\n",
            "Epoch 234/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0036 - val_loss: 0.0237\n",
            "Epoch 235/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0037 - val_loss: 0.0236\n",
            "Epoch 236/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0036 - val_loss: 0.0239\n",
            "Epoch 237/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0036 - val_loss: 0.0238\n",
            "Epoch 238/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0036 - val_loss: 0.0238\n",
            "Epoch 239/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0036 - val_loss: 0.0238\n",
            "Epoch 240/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0036 - val_loss: 0.0238\n",
            "Epoch 241/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0036 - val_loss: 0.0237\n",
            "Epoch 242/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0035 - val_loss: 0.0238\n",
            "Epoch 243/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0035 - val_loss: 0.0238\n",
            "Epoch 244/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0035 - val_loss: 0.0237\n",
            "Epoch 245/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0035 - val_loss: 0.0238\n",
            "Epoch 246/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0036 - val_loss: 0.0238\n",
            "Epoch 247/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0035 - val_loss: 0.0239\n",
            "Epoch 248/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0035 - val_loss: 0.0239\n",
            "Epoch 249/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0035 - val_loss: 0.0239\n",
            "Epoch 250/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0035 - val_loss: 0.0239\n",
            "Epoch 251/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0035 - val_loss: 0.0240\n",
            "Epoch 252/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0035 - val_loss: 0.0238\n",
            "Epoch 253/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0035 - val_loss: 0.0239\n",
            "Epoch 254/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0035 - val_loss: 0.0238\n",
            "Epoch 255/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0035 - val_loss: 0.0239\n",
            "Epoch 256/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0240\n",
            "Epoch 257/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0240\n",
            "Epoch 258/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0239\n",
            "Epoch 259/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0240\n",
            "Epoch 260/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0034 - val_loss: 0.0240\n",
            "Epoch 261/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0241\n",
            "Epoch 262/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0241\n",
            "Epoch 263/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0241\n",
            "Epoch 264/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0240\n",
            "Epoch 265/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0239\n",
            "Epoch 266/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0239\n",
            "Epoch 267/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0240\n",
            "Epoch 268/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0034 - val_loss: 0.0240\n",
            "Epoch 269/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0034 - val_loss: 0.0240\n",
            "Epoch 270/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0033 - val_loss: 0.0241\n",
            "Epoch 271/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0242\n",
            "Epoch 272/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0241\n",
            "Epoch 273/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0241\n",
            "Epoch 274/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0033 - val_loss: 0.0240\n",
            "Epoch 275/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0033 - val_loss: 0.0242\n",
            "Epoch 276/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0241\n",
            "Epoch 277/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0241\n",
            "Epoch 278/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0239\n",
            "Epoch 279/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0033 - val_loss: 0.0240\n",
            "Epoch 280/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0033 - val_loss: 0.0241\n",
            "Epoch 281/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0240\n",
            "Epoch 282/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0241\n",
            "Epoch 283/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0033 - val_loss: 0.0241\n",
            "Epoch 284/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0241\n",
            "Epoch 285/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0032 - val_loss: 0.0241\n",
            "Epoch 286/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0242\n",
            "Epoch 287/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0242\n",
            "Epoch 288/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0241\n",
            "Epoch 289/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0032 - val_loss: 0.0240\n",
            "Epoch 290/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0032 - val_loss: 0.0243\n",
            "Epoch 291/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0242\n",
            "Epoch 292/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0242\n",
            "Epoch 293/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0032 - val_loss: 0.0243\n",
            "Epoch 294/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0241\n",
            "Epoch 295/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 296/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0243\n",
            "Epoch 297/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0246\n",
            "Epoch 298/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0032 - val_loss: 0.0243\n",
            "Epoch 299/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0032 - val_loss: 0.0244\n",
            "Epoch 300/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0031 - val_loss: 0.0242\n",
            "Epoch 301/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 302/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0031 - val_loss: 0.0245\n",
            "Epoch 303/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 304/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 305/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 306/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0242\n",
            "Epoch 307/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 308/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0244\n",
            "Epoch 309/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 310/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0242\n",
            "Epoch 311/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0244\n",
            "Epoch 312/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0032 - val_loss: 0.0244\n",
            "Epoch 313/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0245\n",
            "Epoch 314/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0244\n",
            "Epoch 315/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 316/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0030 - val_loss: 0.0244\n",
            "Epoch 317/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0031 - val_loss: 0.0244\n",
            "Epoch 318/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0242\n",
            "Epoch 319/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0244\n",
            "Epoch 320/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0244\n",
            "Epoch 321/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0030 - val_loss: 0.0245\n",
            "Epoch 322/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0030 - val_loss: 0.0244\n",
            "Epoch 323/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0244\n",
            "Epoch 324/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0244\n",
            "Epoch 325/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0245\n",
            "Epoch 326/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0030 - val_loss: 0.0243\n",
            "Epoch 327/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0030 - val_loss: 0.0243\n",
            "Epoch 328/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0246\n",
            "Epoch 329/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0244\n",
            "Epoch 330/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0245\n",
            "Epoch 331/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 332/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0029 - val_loss: 0.0244\n",
            "Epoch 333/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0030 - val_loss: 0.0245\n",
            "Epoch 334/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0031 - val_loss: 0.0243\n",
            "Epoch 335/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0244\n",
            "Epoch 336/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0245\n",
            "Epoch 337/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0244\n",
            "Epoch 338/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 339/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 340/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 341/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 342/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 343/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 344/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 345/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 346/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0247\n",
            "Epoch 347/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 348/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 349/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 350/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0030 - val_loss: 0.0244\n",
            "Epoch 351/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 352/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0245\n",
            "Epoch 353/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 354/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0248\n",
            "Epoch 355/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 356/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 357/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0029 - val_loss: 0.0247\n",
            "Epoch 358/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 359/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0028 - val_loss: 0.0247\n",
            "Epoch 360/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 361/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0245\n",
            "Epoch 362/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 363/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 364/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0029 - val_loss: 0.0247\n",
            "Epoch 365/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0029 - val_loss: 0.0247\n",
            "Epoch 366/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0249\n",
            "Epoch 367/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0247\n",
            "Epoch 368/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 369/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 370/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0028 - val_loss: 0.0247\n",
            "Epoch 371/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0245\n",
            "Epoch 372/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0247\n",
            "Epoch 373/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0247\n",
            "Epoch 374/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0028 - val_loss: 0.0247\n",
            "Epoch 375/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0028 - val_loss: 0.0247\n",
            "Epoch 376/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0027 - val_loss: 0.0247\n",
            "Epoch 377/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0029 - val_loss: 0.0246\n",
            "Epoch 378/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 379/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0247\n",
            "Epoch 380/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 381/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0028 - val_loss: 0.0248\n",
            "Epoch 382/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0246\n",
            "Epoch 383/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0248\n",
            "Epoch 384/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0247\n",
            "Epoch 385/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0028 - val_loss: 0.0245\n",
            "Epoch 386/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0030 - val_loss: 0.0246\n",
            "Epoch 387/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 388/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0246\n",
            "Epoch 389/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0247\n",
            "Epoch 390/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0247\n",
            "Epoch 391/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 392/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0027 - val_loss: 0.0247\n",
            "Epoch 393/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 394/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0028 - val_loss: 0.0246\n",
            "Epoch 395/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0246\n",
            "Epoch 396/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 397/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0027 - val_loss: 0.0247\n",
            "Epoch 398/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0027 - val_loss: 0.0247\n",
            "Epoch 399/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0248\n",
            "Epoch 400/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 401/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0027 - val_loss: 0.0248\n",
            "Epoch 402/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 403/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0027 - val_loss: 0.0248\n",
            "Epoch 404/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0027 - val_loss: 0.0247\n",
            "Epoch 405/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0248\n",
            "Epoch 406/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0248\n",
            "Epoch 407/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0248\n",
            "Epoch 408/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 409/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 410/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0248\n",
            "Epoch 411/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 412/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0248\n",
            "Epoch 413/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0247\n",
            "Epoch 414/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 415/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 416/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0247\n",
            "Epoch 417/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 418/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0027 - val_loss: 0.0249\n",
            "Epoch 419/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0248\n",
            "Epoch 420/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 421/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0248\n",
            "Epoch 422/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 423/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0247\n",
            "Epoch 424/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 425/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 426/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0248\n",
            "Epoch 427/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0248\n",
            "Epoch 428/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 429/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0248\n",
            "Epoch 430/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 431/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 432/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 433/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 434/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 435/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 436/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 437/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 438/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 439/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 440/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 441/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 442/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 443/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0248\n",
            "Epoch 444/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 445/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 446/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0251\n",
            "Epoch 447/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 448/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0249\n",
            "Epoch 449/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 450/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 451/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 452/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 453/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 454/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 455/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 456/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 457/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0249\n",
            "Epoch 458/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0026 - val_loss: 0.0248\n",
            "Epoch 459/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 460/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 461/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 462/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 463/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0250\n",
            "Epoch 464/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 465/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 466/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 467/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 468/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 469/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0026 - val_loss: 0.0249\n",
            "Epoch 470/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0249\n",
            "Epoch 471/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 472/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 473/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0024 - val_loss: 0.0251\n",
            "Epoch 474/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 475/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 476/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 477/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 478/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 479/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0249\n",
            "Epoch 480/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0024 - val_loss: 0.0250\n",
            "Epoch 481/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0250\n",
            "Epoch 482/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 483/500\n",
            "396/396 [==============================] - 12s 30ms/step - loss: 0.0025 - val_loss: 0.0252\n",
            "Epoch 484/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0024 - val_loss: 0.0251\n",
            "Epoch 485/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 486/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 487/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0252\n",
            "Epoch 488/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0024 - val_loss: 0.0250\n",
            "Epoch 489/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 490/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0024 - val_loss: 0.0252\n",
            "Epoch 491/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0025 - val_loss: 0.0252\n",
            "Epoch 492/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0024 - val_loss: 0.0252\n",
            "Epoch 493/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0024 - val_loss: 0.0252\n",
            "Epoch 494/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 495/500\n",
            "396/396 [==============================] - 12s 31ms/step - loss: 0.0025 - val_loss: 0.0251\n",
            "Epoch 496/500\n",
            "396/396 [==============================] - 11s 27ms/step - loss: 0.0025 - val_loss: 0.0252\n",
            "Epoch 497/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0024 - val_loss: 0.0249\n",
            "Epoch 498/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0024 - val_loss: 0.0251\n",
            "Epoch 499/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0024 - val_loss: 0.0251\n",
            "Epoch 500/500\n",
            "396/396 [==============================] - 11s 28ms/step - loss: 0.0024 - val_loss: 0.0251\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        640       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 369664 (1.41 MB)\n",
            "Trainable params: 369664 (1.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "The time of execution of above program is : 5610.426378965378 seconds\n"
          ]
        }
      ]
    }
  ]
}