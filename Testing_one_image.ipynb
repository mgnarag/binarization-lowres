{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/binarization-lowres/blob/main/Testing_one_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4a6w1GsajIN",
        "outputId": "b9c4514a-37e9-4a27-bcaa-0547dac0bb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKh0dJSzaj_X"
      },
      "outputs": [],
      "source": [
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/My Drive/Architectural_designs/From Arki/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7KGh6L6qVZ8b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import time\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4TkaTAC3zgr7"
      },
      "outputs": [],
      "source": [
        "def crop(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdJThYVg8IpL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt = Image.open(file_path+ '4 Testing/ground_truth_100dpi.png').convert('L')\n",
        "img_gt = cv2.imread(file_path+ '4 Testing/ground_truth_100dpi.png')\n",
        "gt = np.asarray(gt) > 128\n",
        "gt = ~gt\n",
        "\n",
        "filename = \"nbs_100dpi_wb.png\"\n",
        "directory = file_path + '4 Testing/' + filename\n",
        "#directory = 'test_output_v'+str(model)+'.png'\n",
        "image = Image.open(directory)\n",
        "rgb = image.convert(\"RGB\")\n",
        "r, g, b = rgb.split()\n",
        "w_dirty, h_dirty = r.size\n",
        "\n",
        "gray = ImageOps.grayscale(Image.open(directory))\n",
        "gray = np.array(gray)\n",
        "gray = Image.fromarray(gray.astype('uint8'))\n",
        "\n",
        "\n",
        "dirty = [gray,r,g,b]\n",
        "\n",
        "\n",
        "METRIC = []\n",
        "channel = ['gray','red','green', 'blue']\n",
        "for model in range(1,7):\n",
        "  for color in range(0,4):\n",
        "      print('Model = ', model, '', str(channel[color]))\n",
        "      from tensorflow import keras\n",
        "      autoencoder = keras.models.load_model(file_path + '1 Models/100 DPI white balanced and bw output/autoencoder_'+str(model)+ '_'+str(channel[color]))\n",
        "      if model == 1:\n",
        "          n_size = 32\n",
        "      if model == 2:\n",
        "          n_size = 32\n",
        "      if model == 3:\n",
        "          n_size = 64\n",
        "      if model == 4:\n",
        "          n_size = 64\n",
        "      if model == 5:\n",
        "          n_size = 128\n",
        "      if model == 6:\n",
        "          n_size = 128\n",
        "      if model == 7:\n",
        "          n_size = 256\n",
        "      if model == 8:\n",
        "          n_size = 256\n",
        "\n",
        "      xx = int(w_dirty/n_size)\n",
        "      final=[]\n",
        "\n",
        "      for portion in range(0,xx):\n",
        "          test = dirty[color]\n",
        "          im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "          w1, h1 = im1.size\n",
        "          w = int(w1/n_size)\n",
        "          h = int(h1/n_size)\n",
        "\n",
        "          neverbeforeseen = np.array(crop(im1))\n",
        "          encoded_imgs = autoencoder.encoder(neverbeforeseen).numpy()\n",
        "          decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "          col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "          for i in range(2,h):\n",
        "              col = np.vstack((col,decoded_imgs[i]))\n",
        "\n",
        "          y = np.where(col > 0.5,1,0) #round the values\n",
        "          y = (y * 255).astype('uint8')\n",
        "          if portion == 0:\n",
        "              final = y\n",
        "          if portion > 0:\n",
        "              final = np.hstack((final,y))\n",
        "\n",
        "      final = np.squeeze(final)\n",
        "      reconstructed = Image.fromarray(final)\n",
        "      #reconstructed.save(file_path + \"5 Tested/output v\" + str(model) + '_'+str(channel[color]) + '.png')\n",
        "\n",
        "      output = Image.open(file_path + \"5 Tested/output v\" + str(model)  + '_'+str(channel[color]) +  '.png').convert('L')  # convert to grayscale\n",
        "      img_out = cv2.imread(file_path + \"5 Tested/output v\" + str(model)  + '_'+str(channel[color]) +  '.png')\n",
        "\n",
        "      output = np.asarray(output) > 128 # Convert to binary images\n",
        "      output = ~output\n",
        "\n",
        "      tp = np.sum(output & gt)\n",
        "      fp = np.sum(output & ~gt)\n",
        "      fn = np.sum(~output & gt)\n",
        "      precision = tp / (tp + fp)\n",
        "      recall = tp / (tp + fn)\n",
        "      f1score = (2*precision*recall)/(precision + recall)\n",
        "\n",
        "      I_1 = output & gt\n",
        "      U_1 = output | gt\n",
        "      I = np.sum(output & gt)\n",
        "      U = np.sum(output | gt)\n",
        "      i_o_u = I/U\n",
        "\n",
        "      psnr = cv2.PSNR(img_out, img_gt)\n",
        "\n",
        "      METRIC.append([model, str(channel[color]), precision,recall,f1score,i_o_u,psnr])\n",
        "  #COMBINING RGB ------------------------------------------------\n",
        "  print('Model = ', model, '', str('RGB'))\n",
        "  output_red = (np.asarray(Image.open(file_path + \"5 Tested/output v\" + str(model)  + '_'+str(channel[0]) +  '.png').convert('L'))>128)\n",
        "  output_green = (np.asarray(Image.open(file_path + \"5 Tested/output v\" + str(model)  + '_'+str(channel[1]) +  '.png').convert('L'))>128)\n",
        "  output_blue = (np.asarray(Image.open(file_path + \"5 Tested/output v\" + str(model)  + '_'+str(channel[2]) +  '.png').convert('L'))>128)\n",
        "  output_rgb = ~output_red | ~output_green | ~output_blue\n",
        "\n",
        "  reconstructed = Image.fromarray(~output_rgb)\n",
        "  #reconstructed.save(file_path + \"5 Tested/output v\" + str(model) + '_RGB.png')\n",
        "\n",
        "  output = Image.open(file_path + \"5 Tested/output v\" + str(model)  + '_RGB.png').convert('L')  # convert to grayscale\n",
        "  img_out = cv2.imread(file_path + \"5 Tested/output v\" + str(model) + '_RGB.png')\n",
        "\n",
        "  output = np.asarray(output) > 128\n",
        "  output = ~output\n",
        "\n",
        "  tp = np.sum(output & gt)\n",
        "  fp = np.sum(output & ~gt)\n",
        "  fn = np.sum(~output & gt)\n",
        "  precision = tp / (tp + fp)\n",
        "  recall = tp / (tp + fn)\n",
        "  f1score = (2*precision*recall)/(precision + recall)\n",
        "\n",
        "  I_1 = output & gt\n",
        "  O_1 = output | gt\n",
        "  I = np.sum(output & gt)\n",
        "  O = np.sum(output | gt)\n",
        "  i_o_u = I/O\n",
        "\n",
        "  psnr = cv2.PSNR(img_out, img_gt)\n",
        "\n",
        "  METRIC.append([model, str('RGB'), precision,recall,f1score,i_o_u,psnr])\n",
        "  #COMBINING RGB plus grayscale------------------------------------------------\n",
        "  print('Model = ', model, '', str('RGB+gray'))\n",
        "  output_gray = (np.asarray(Image.open(file_path + \"5 Tested/output v\" + str(model) +  '_gray.png').convert('L'))>128)\n",
        "  output = output_rgb | ~output_gray\n",
        "\n",
        "  reconstructed = Image.fromarray(~output)\n",
        "  #reconstructed.save(file_path + \"5 Tested/output v\" + str(model) + '_RGB_GRAY.png')\n",
        "\n",
        "  output = Image.open(file_path + \"5 Tested/output v\" + str(model)  + '_RGB_GRAY.png').convert('L')  # convert to grayscale\n",
        "  img_out = cv2.imread(file_path + \"5 Tested/output v\" + str(model) + '_RGB_GRAY.png')\n",
        "\n",
        "  output = np.asarray(output) > 128\n",
        "  output = ~output\n",
        "\n",
        "  tp = np.sum(output & gt)\n",
        "  fp = np.sum(output & ~gt)\n",
        "  fn = np.sum(~output & gt)\n",
        "  precision = tp / (tp + fp)\n",
        "  recall = tp / (tp + fn)\n",
        "  f1score = (2*precision*recall)/(precision + recall)\n",
        "\n",
        "  I_1 = output & gt\n",
        "  O_1 = output | gt\n",
        "  I = np.sum(output & gt)\n",
        "  O = np.sum(output | gt)\n",
        "  i_o_u = I/O\n",
        "\n",
        "  psnr = cv2.PSNR(img_out, img_gt)\n",
        "\n",
        "  METRIC.append([model, str('RGB+gray'),precision,recall,f1score,i_o_u,psnr])\n",
        "\n",
        "\n",
        "METRIC = pd.DataFrame(METRIC)\n",
        "\n",
        "headers = ['Model','Channel','Precision', 'Recall', 'F1 Score', 'IOU','PSNR' ]\n",
        "METRIC.columns = headers\n",
        "\n",
        "METRIC.to_csv(file_path + '[B] 100 DPI white balanced and bw output.csv')\n",
        "print(METRIC)"
      ],
      "metadata": {
        "id": "lVaBudLqydfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "directory = file_path + \"6 Traditional Binarization/nbs_whole_WB.png\"\n",
        "image = Image.open(directory)\n",
        "rgb = image.convert(\"RGB\")\n",
        "r, g, b = rgb.split()\n",
        "w_dirty, h_dirty = r.size\n",
        "\n",
        "\n",
        "dirty = [r,g,b]\n",
        "\n",
        "channel = ['gray','red','green', 'blue']\n",
        "model = 3\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for color in range(0,3):\n",
        "    autoencoder = keras.models.load_model(file_path + '1 Models/100 DPI white balanced and bw output/autoencoder_'+str(model)+ '_'+str(channel[color]))\n",
        "    n_size = 32\n",
        "\n",
        "    xx = int(w_dirty/n_size)\n",
        "    final=[]\n",
        "\n",
        "    for portion in range(0,xx):\n",
        "        test = dirty[color]\n",
        "        im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "        w1, h1 = im1.size\n",
        "        w = int(w1/n_size)\n",
        "        h = int(h1/n_size)\n",
        "\n",
        "        neverbeforeseen = np.array(crop(im1))\n",
        "        encoded_imgs = autoencoder.encoder(neverbeforeseen).numpy()\n",
        "        decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "        col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "        for i in range(2,h):\n",
        "            col = np.vstack((col,decoded_imgs[i]))\n",
        "\n",
        "        y = np.where(col > 0.5,1,0) #round the values\n",
        "        y = (y * 255).astype('uint8')\n",
        "        if portion == 0:\n",
        "            final = y\n",
        "        if portion > 0:\n",
        "            final = np.hstack((final,y))\n",
        "\n",
        "    final = np.squeeze(final)\n",
        "    reconstructed = Image.fromarray(final)\n",
        "    reconstructed.save(file_path + \"6 Traditional Binarization/output v_\" +str(channel[color]) + '.png')\n",
        "#COMBINING RGB ------------------------------------------------\n",
        "print('Model = ', model, '', str('RGB'))\n",
        "output_red = (np.asarray(Image.open(file_path + \"6 Traditional Binarization/output v_\" +str(channel[0]) +  '.png').convert('L'))>128)\n",
        "output_green = (np.asarray(Image.open(file_path + \"6 Traditional Binarization/output v_\" +str(channel[1]) +  '.png').convert('L'))>128)\n",
        "output_blue = (np.asarray(Image.open(file_path + \"6 Traditional Binarization/output v_\" +str(channel[2]) +  '.png').convert('L'))>128)\n",
        "output_rgb = ~output_red | ~output_green | ~output_blue\n",
        "\n",
        "reconstructed = Image.fromarray(~output_rgb)\n",
        "reconstructed.save(file_path + \"6 Traditional Binarization/output_RGB.png\")\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        "\n",
        "print(\"Execution time :\",\n",
        "      (end-start), \"seconds\")"
      ],
      "metadata": {
        "id": "-6lDL9udzK00",
        "outputId": "7ee193dd-bf4c-4d3e-8c9a-a33683899538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-179dfaaab2cc>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mneverbeforeseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneverbeforeseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    299\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 64, 64, 1), found shape=(132, 32, 32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7uZdFCvPxiC",
        "outputId": "77599b24-561c-4bb7-b529-7e868d2b6878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2009: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  result = asarray(a).shape\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "\n",
        "filename = \"nbs_whole_WB.png\"\n",
        "directory = file_path + '6 Traditional Binarization/' + filename\n",
        "#directory = 'test_output_v'+str(model)+'.png'\n",
        "image = Image.open(directory)\n",
        "rgb = image.convert(\"RGB\")\n",
        "r, g, b = rgb.split()\n",
        "w_dirty, h_dirty = r.size\n",
        "\n",
        "gray = ImageOps.grayscale(Image.open(directory))\n",
        "gray = np.array(gray)\n",
        "gray = Image.fromarray(gray.astype('uint8'))\n",
        "\n",
        "dirty = [gray,r,g,b]\n",
        "\n",
        "\n",
        "METRIC = []\n",
        "channel = ['gray','red','green', 'blue']\n",
        "for model in range(3,4):\n",
        "  for color in range(1,4):\n",
        "      print('Model = ', model, '', str(channel[color]))\n",
        "      from tensorflow import keras\n",
        "      autoencoder = keras.models.load_model(file_path + '1 Models/100 DPI white balanced and bw output/autoencoder_'+str(model)+ '_'+str(channel[color]))\n",
        "      if model == 1:\n",
        "          n_size = 32\n",
        "      if model == 2:\n",
        "          n_size = 32\n",
        "      if model == 3:\n",
        "          n_size = 64\n",
        "      if model == 4:\n",
        "          n_size = 64\n",
        "      if model == 5:\n",
        "          n_size = 128\n",
        "      if model == 6:\n",
        "          n_size = 128\n",
        "      if model == 7:\n",
        "          n_size = 256\n",
        "      if model == 8:\n",
        "          n_size = 256\n",
        "\n",
        "      xx = int(w_dirty/n_size)\n",
        "      final=[]\n",
        "\n",
        "      for portion in range(0,xx):\n",
        "          test = dirty[color]\n",
        "          im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "          w1, h1 = im1.size\n",
        "          w = int(w1/n_size)\n",
        "          h = int(h1/n_size)\n",
        "\n",
        "          neverbeforeseen = np.array(crop(im1))\n",
        "          encoded_imgs = autoencoder.encoder(neverbeforeseen).numpy()\n",
        "          decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "          col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "          for i in range(2,h):\n",
        "              col = np.vstack((col,decoded_imgs[i]))\n",
        "\n",
        "          y = np.where(col > 0.5,1,0) #round the values\n",
        "          y = (y * 255).astype('uint8')\n",
        "          if portion == 0:\n",
        "              final = y\n",
        "          if portion > 0:\n",
        "              final = np.hstack((final,y))\n",
        "\n",
        "      final = np.squeeze(final)\n",
        "      reconstructed = Image.fromarray(final)\n",
        "      reconstructed.save(file_path + \"6 Traditional Binarization/output v\" + str(model) + '_'+str(channel[color]) + '.png')\n",
        "  #COMBINING RGB ------------------------------------------------\n",
        "  print('Model = ', model, '', str('RGB'))\n",
        "  output_red = (np.asarray(Image.open(file_path + \"6 Traditional Binarization/output v\" + str(model)  + '_'+str(channel[1]) +  '.png').convert('L'))>128)\n",
        "  output_green = (np.asarray(Image.open(file_path + \"6 Traditional Binarization/output v\" + str(model)  + '_'+str(channel[2]) +  '.png').convert('L'))>128)\n",
        "  output_blue = (np.asarray(Image.open(file_path + \"6 Traditional Binarization/output v\" + str(model)  + '_'+str(channel[3]) +  '.png').convert('L'))>128)\n",
        "  output_rgb = ~output_red | ~output_green | ~output_blue\n",
        "\n",
        "  reconstructed = Image.fromarray(~output_rgb)\n",
        "  reconstructed.save(file_path + \"6 Traditional Binarization/output v\" + str(model) + '_RGB.png')\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        "\n",
        "print(\"Execution time :\",\n",
        "      (end-start), \"seconds\")\n"
      ],
      "metadata": {
        "id": "GslrlppgQLck",
        "outputId": "b1449f3f-861d-493c-c365-21112b8dba8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model =  3  red\n",
            "Model =  3  green\n",
            "Model =  3  blue\n",
            "Model =  3  RGB\n",
            "Execution time : 1038.7171921730042 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}