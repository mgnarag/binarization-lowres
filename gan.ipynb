{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-W7VpZj-bMM"
      },
      "source": [
        "Generative Adversarial Networks (GANs)\n",
        "======\n",
        "This code implements a Deep Convolutional GAN (DCGAN), a GAN with only convolutional layers in the encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hDikNOI--bMP",
        "outputId": "ead10c0f-2317-4a8b-94d5-b0d5239cfe22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `pip install pytorch (http://pytorch.org/) if run from Google Colaboratory'\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch (http://pytorch.org/) if run from Google Colaboratory\n",
        "import sys\n",
        "if 'google.colab' in sys.modules and 'torch' not in sys.modules:\n",
        "    from os.path import exists\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "    !pip3 install https://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl\n",
        "    !pip3 install https://download.pytorch.org/whl/{accelerator}/torchvision-0.3.0-{platform}-linux_x86_64.whl\n",
        "\n",
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2OeIlMn-bMR"
      },
      "source": [
        "Parameter Settings\n",
        "-------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_9KV4nwR-bMR"
      },
      "outputs": [],
      "source": [
        "latent_dims = 10\n",
        "num_epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = 2e-4\n",
        "use_gpu = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUTaTNKC-bMR"
      },
      "source": [
        "MNIST Data Loading\n",
        "-------------------\n",
        "\n",
        "MNIST images show digits from 0-9 in 28x28 grayscale images. We scale to 64x64 so we can have a deeper architecture with more down-sampling steps. The images are normalized and centerd around 0, which gives a slight performance boost during training. We create both a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I_o1mN3d-bMS"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBQmGztv-bMS"
      },
      "source": [
        "GAN Definition\n",
        "-----------------------\n",
        "We use a convolutional generator and discriminator, which generally gives better performance than fully connected versions that have the same number of parameters.\n",
        "\n",
        "Kernel size 4 is used to avoid biasing problems described here: https://distill.pub/2016/deconv-checkerboard/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gv_hpsHx-bMS",
        "outputId": "151abac0-9ab1-4406-cdea-8e04141ae514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters for generator: 12656257 and discriminator: 11033985\n"
          ]
        }
      ],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, d=128):\n",
        "        super(Generator, self).__init__()\n",
        "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # x = F.relu(self.deconv1(input))\n",
        "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
        "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = torch.tanh(self.deconv5(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d=128):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "generator = generator.to(device)\n",
        "discriminator = discriminator.to(device)\n",
        "\n",
        "num_params_gen = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
        "num_params_disc = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
        "print('Number of parameters for generator: %d and discriminator: %d' % (num_params_gen, num_params_disc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umo1Cy-T-bMT"
      },
      "source": [
        "Train GAN\n",
        "--------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "id": "_GU-nxFm-bMU",
        "outputId": "9d944c53-444a-44ac-93d7-a93b43896eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ...\n",
            "Epoch [1 / 20] average loss generator vs. discrim.: 5.854479 vs. 0.325840\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0b9bb0aa9b17>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mgen_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mgen_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# GAN training can be unstable. In this case, the strong momentum\n",
        "# for the gradient prevents convergence. One possible explanation is that the\n",
        "# strong momentum does not allow the two players in the adversarial game to react\n",
        "# to each other quickly enough. Decreasing beta1 (the exponential decay for the\n",
        "# gradient moving average in [0,1], lower is faster decay) from the default 0.9\n",
        "# to 0.5 allows for quicker reactions.\n",
        "gen_optimizer = torch.optim.Adam(params=generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "disc_optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "\n",
        "# set to training mode\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "\n",
        "gen_loss_avg = []\n",
        "disc_loss_avg = []\n",
        "\n",
        "print('Training ...')\n",
        "for epoch in range(num_epochs):\n",
        "    gen_loss_avg.append(0)\n",
        "    disc_loss_avg.append(0)\n",
        "    num_batches = 0\n",
        "\n",
        "    for image_batch, _ in train_dataloader:\n",
        "\n",
        "        # get dataset image and create real and fake labels for use in the loss\n",
        "        image_batch = image_batch.to(device)\n",
        "        label_real = torch.ones(image_batch.size(0), device=device)\n",
        "        label_fake = torch.zeros(image_batch.size(0), device=device)\n",
        "\n",
        "        # generate a batch of images from samples of the latent prior\n",
        "        latent = torch.randn(image_batch.size(0), 100, 1, 1, device=device)\n",
        "        fake_image_batch = generator(latent)\n",
        "\n",
        "        # train discriminator to correctly classify real and fake\n",
        "        # (detach the computation graph of the generator and the discriminator,\n",
        "        # so that gradients are not backpropagated into the generator)\n",
        "        real_pred = discriminator(image_batch).squeeze()\n",
        "        fake_pred = discriminator(fake_image_batch.detach()).squeeze()\n",
        "        disc_loss = 0.5 * (\n",
        "            F.binary_cross_entropy(real_pred, label_real) +\n",
        "            F.binary_cross_entropy(fake_pred, label_fake))\n",
        "\n",
        "        disc_optimizer.zero_grad()\n",
        "        disc_loss.backward()\n",
        "        disc_optimizer.step()\n",
        "\n",
        "        # train generator to output an image that is classified as real\n",
        "        fake_pred = discriminator(fake_image_batch).squeeze()\n",
        "        gen_loss = F.binary_cross_entropy(fake_pred, label_real)\n",
        "\n",
        "        gen_optimizer.zero_grad()\n",
        "        gen_loss.backward()\n",
        "        gen_optimizer.step()\n",
        "\n",
        "        gen_loss_avg[-1] += gen_loss.item()\n",
        "        disc_loss_avg[-1] += disc_loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    gen_loss_avg[-1] /= num_batches\n",
        "    disc_loss_avg[-1] /= num_batches\n",
        "    print('Epoch [%d / %d] average loss generator vs. discrim.: %f vs. %f' %\n",
        "          (epoch+1, num_epochs, gen_loss_avg[-1], disc_loss_avg[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dotxGYId-bMV"
      },
      "source": [
        "Plot Training Curves\n",
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6oMD4lV-bMV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(gen_loss_avg, label='generator')\n",
        "plt.plot(disc_loss_avg, label='discriminator')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY7n_Ieg-bMW"
      },
      "source": [
        "Alternatively: Load Pre-Trained GAN\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM5iRcdD-bMW"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "if not os.path.isdir('./pretrained'):\n",
        "    os.makedirs('./pretrained')\n",
        "print('downloading ...')\n",
        "urllib.request.urlretrieve (\"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/dcgan.pth\", \"./pretrained/dcgan.pth\")\n",
        "urllib.request.urlretrieve (\"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/dcgan_discriminator.pth\", \"./pretrained/dcgan_discriminator.pth\")\n",
        "generator.load_state_dict(torch.load('./pretrained/dcgan.pth'))\n",
        "discriminator.load_state_dict(torch.load('./pretrained/dcgan_discriminator.pth'))\n",
        "print('done')\n",
        "\n",
        "# this is how the GAN parameters can be saved:\n",
        "# torch.save(generator.state_dict(), './pretrained/my_dcgan.pth')\n",
        "# torch.save(discriminator.state_dict(), './pretrained/my_dcgan_discriminator.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QWvLSNH-bMW"
      },
      "source": [
        "Interpolate in Latent Space\n",
        "----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "-eYEnr7_-bMW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "import torchvision.utils\n",
        "\n",
        "generator.eval()\n",
        "\n",
        "def interpolation(lambda1, model, latent_1, latent_2):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # interpolation of the two latent vectors\n",
        "        inter_latent = lambda1* latent_1 + (1- lambda1) * latent_2\n",
        "\n",
        "        # reconstruct interpolated image\n",
        "        inter_latent = inter_latent.to(device)\n",
        "        inter_image = model(inter_latent)\n",
        "        inter_image = inter_image.cpu()\n",
        "\n",
        "        return inter_image\n",
        "\n",
        "# sample two latent vectors from the standard normal distribution\n",
        "latent_1 = torch.randn(1, 100, 1, 1, device=device)\n",
        "latent_2 = torch.randn(1, 100, 1, 1, device=device)\n",
        "\n",
        "# interpolation lambdas\n",
        "lambda_range=np.linspace(0,1,10)\n",
        "\n",
        "fig, axs = plt.subplots(2,5, figsize=(15, 6))\n",
        "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "\n",
        "for ind,l in enumerate(lambda_range):\n",
        "    inter_image=interpolation(float(l), generator, latent_1, latent_2)\n",
        "\n",
        "    inter_image = to_img(inter_image)\n",
        "\n",
        "    image = inter_image.numpy()\n",
        "\n",
        "    axs[ind].imshow(image[0,0,:,:], cmap='gray')\n",
        "    axs[ind].set_title('lambda_val='+str(round(l,1)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs9xvaSC-bMW"
      },
      "source": [
        "Sample Latent Vector from Prior (GAN as Generator)\n",
        "-------------------------------------------------\n",
        "\n",
        "GANs usually generate higher-quality results than VAEs or plain Autoencoders, since the distribution of generated digits is more focused on the modes of the real data distribution (see tutorial slides). However, they are harder to train and don't have an encoder, which means the inference of a latent code from a given image is not possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX9PBqIS-bMW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "import torchvision.utils\n",
        "\n",
        "generator.eval()\n",
        "\n",
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    return x\n",
        "\n",
        "def show_image(img):\n",
        "    img = to_img(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    # sample latent vectors from the standard normal distribution\n",
        "    latent = torch.randn(image_batch.size(0), 100, 1, 1, device=device)\n",
        "    fake_image_batch = generator(latent)\n",
        "    fake_image_batch = fake_image_batch.cpu()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    show_image(torchvision.utils.make_grid(fake_image_batch.data[:100],10,5))\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}